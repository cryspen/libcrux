	.att_syntax
	.text
	.p2align	5
	.globl	_jade_stream_chacha_chacha20_ietf_amd64_ref
	.globl	jade_stream_chacha_chacha20_ietf_amd64_ref
	.globl	_jade_stream_chacha_chacha20_ietf_amd64_ref_xor
	.globl	jade_stream_chacha_chacha20_ietf_amd64_ref_xor
_jade_stream_chacha_chacha20_ietf_amd64_ref:
jade_stream_chacha_chacha20_ietf_amd64_ref:
	movq	%rsp, %rax
	leaq	-152(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 144(%rsp)
	movq	%rbx, 96(%rsp)
	movq	%rbp, 104(%rsp)
	movq	%r12, 112(%rsp)
	movq	%r13, 120(%rsp)
	movq	%r14, 128(%rsp)
	movq	%r15, 136(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movl	$1634760805, 16(%rsp)
	movl	$857760878, 20(%rsp)
	movl	$2036477234, 24(%rsp)
	movl	$1797285236, 28(%rsp)
	movl	(%rcx), %eax
	movl	%eax, 32(%rsp)
	movl	4(%rcx), %eax
	movl	%eax, 36(%rsp)
	movl	8(%rcx), %eax
	movl	%eax, 40(%rsp)
	movl	12(%rcx), %eax
	movl	%eax, 44(%rsp)
	movl	16(%rcx), %eax
	movl	%eax, 48(%rsp)
	movl	20(%rcx), %eax
	movl	%eax, 52(%rsp)
	movl	24(%rcx), %eax
	movl	%eax, 56(%rsp)
	movl	28(%rcx), %eax
	movl	%eax, 60(%rsp)
	movl	$0, 64(%rsp)
	movl	(%rdx), %eax
	movl	%eax, 68(%rsp)
	movl	4(%rdx), %eax
	movl	%eax, 72(%rsp)
	movl	8(%rdx), %eax
	movl	%eax, 76(%rsp)
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref$7
Ljade_stream_chacha_chacha20_ietf_amd64_ref$8:
	movl	76(%rsp), %eax
	movl	%eax, 80(%rsp)
	movl	16(%rsp), %r14d
	movl	20(%rsp), %r13d
	movl	24(%rsp), %eax
	movl	28(%rsp), %r15d
	movl	32(%rsp), %ecx
	movl	36(%rsp), %edx
	movl	40(%rsp), %esi
	movl	44(%rsp), %edi
	movl	48(%rsp), %r8d
	movl	52(%rsp), %r9d
	movl	56(%rsp), %r10d
	movl	60(%rsp), %r11d
	movl	64(%rsp), %ebx
	movl	68(%rsp), %ebp
	movl	72(%rsp), %r12d
	movl	%r12d, 84(%rsp)
	movl	$10, %r12d
Ljade_stream_chacha_chacha20_ietf_amd64_ref$9:
	movl	%r12d, 88(%rsp)
	movl	84(%rsp), %r12d
	addl	%ecx, %r14d
	addl	%esi, %eax
	xorl	%r14d, %ebx
	xorl	%eax, %r12d
	roll	$16, %ebx
	roll	$16, %r12d
	addl	%ebx, %r8d
	addl	%r12d, %r10d
	xorl	%r8d, %ecx
	xorl	%r10d, %esi
	roll	$12, %ecx
	roll	$12, %esi
	addl	%ecx, %r14d
	addl	%esi, %eax
	xorl	%r14d, %ebx
	xorl	%eax, %r12d
	roll	$8, %ebx
	roll	$8, %r12d
	addl	%ebx, %r8d
	addl	%r12d, %r10d
	xorl	%r8d, %ecx
	xorl	%r10d, %esi
	roll	$7, %ecx
	roll	$7, %esi
	movl	%r12d, 92(%rsp)
	movl	80(%rsp), %r12d
	addl	%edx, %r13d
	addl	%edi, %r15d
	xorl	%r13d, %ebp
	xorl	%r15d, %r12d
	roll	$16, %ebp
	roll	$16, %r12d
	addl	%ebp, %r9d
	addl	%r12d, %r11d
	xorl	%r9d, %edx
	xorl	%r11d, %edi
	roll	$12, %edx
	roll	$12, %edi
	addl	%edx, %r13d
	addl	%edi, %r15d
	xorl	%r13d, %ebp
	xorl	%r15d, %r12d
	roll	$8, %ebp
	roll	$8, %r12d
	addl	%ebp, %r9d
	addl	%r12d, %r11d
	xorl	%r9d, %edx
	xorl	%r11d, %edi
	roll	$7, %edx
	roll	$7, %edi
	addl	%esi, %r13d
	addl	%edx, %r14d
	xorl	%r13d, %ebx
	xorl	%r14d, %r12d
	roll	$16, %ebx
	roll	$16, %r12d
	addl	%ebx, %r11d
	addl	%r12d, %r10d
	xorl	%r11d, %esi
	xorl	%r10d, %edx
	roll	$12, %esi
	roll	$12, %edx
	addl	%esi, %r13d
	addl	%edx, %r14d
	xorl	%r13d, %ebx
	xorl	%r14d, %r12d
	roll	$8, %ebx
	roll	$8, %r12d
	addl	%ebx, %r11d
	addl	%r12d, %r10d
	xorl	%r11d, %esi
	xorl	%r10d, %edx
	roll	$7, %esi
	roll	$7, %edx
	movl	%r12d, 80(%rsp)
	movl	92(%rsp), %r12d
	addl	%edi, %eax
	addl	%ecx, %r15d
	xorl	%eax, %ebp
	xorl	%r15d, %r12d
	roll	$16, %ebp
	roll	$16, %r12d
	addl	%ebp, %r8d
	addl	%r12d, %r9d
	xorl	%r8d, %edi
	xorl	%r9d, %ecx
	roll	$12, %edi
	roll	$12, %ecx
	addl	%edi, %eax
	addl	%ecx, %r15d
	xorl	%eax, %ebp
	xorl	%r15d, %r12d
	roll	$8, %ebp
	roll	$8, %r12d
	addl	%ebp, %r8d
	addl	%r12d, %r9d
	xorl	%r8d, %edi
	xorl	%r9d, %ecx
	roll	$7, %edi
	roll	$7, %ecx
	movl	%r12d, 84(%rsp)
	movl	88(%rsp), %r12d
	decl	%r12d
	cmpl	$0, %r12d
	jnbe	Ljade_stream_chacha_chacha20_ietf_amd64_ref$9
	movl	84(%rsp), %r12d
	addl	20(%rsp), %r13d
	addl	16(%rsp), %r14d
	movl	%r13d, %r13d
	shlq	$32, %r13
	movl	%r14d, %r14d
	xorq	%r14, %r13
	addl	28(%rsp), %r15d
	addl	24(%rsp), %eax
	movl	%r15d, %r14d
	shlq	$32, %r14
	movl	%eax, %eax
	xorq	%rax, %r14
	movq	(%rsp), %rax
	movq	%r13, (%rax)
	addl	36(%rsp), %edx
	addl	32(%rsp), %ecx
	movl	%edx, %edx
	shlq	$32, %rdx
	movl	%ecx, %ecx
	xorq	%rcx, %rdx
	movq	%r14, 8(%rax)
	addl	44(%rsp), %edi
	addl	40(%rsp), %esi
	movl	%edi, %ecx
	shlq	$32, %rcx
	movl	%esi, %esi
	xorq	%rsi, %rcx
	movq	%rdx, 16(%rax)
	addl	52(%rsp), %r9d
	addl	48(%rsp), %r8d
	movl	%r9d, %edx
	shlq	$32, %rdx
	movl	%r8d, %esi
	xorq	%rsi, %rdx
	movq	%rcx, 24(%rax)
	addl	60(%rsp), %r11d
	addl	56(%rsp), %r10d
	movl	%r11d, %ecx
	shlq	$32, %rcx
	movl	%r10d, %esi
	xorq	%rsi, %rcx
	movq	%rdx, 32(%rax)
	addl	68(%rsp), %ebp
	addl	64(%rsp), %ebx
	movl	%ebp, %edx
	shlq	$32, %rdx
	movl	%ebx, %esi
	xorq	%rsi, %rdx
	movq	%rcx, 40(%rax)
	movl	80(%rsp), %ecx
	addl	76(%rsp), %ecx
	addl	72(%rsp), %r12d
	movl	%ecx, %ecx
	shlq	$32, %rcx
	movl	%r12d, %esi
	xorq	%rsi, %rcx
	movq	%rdx, 48(%rax)
	movq	%rcx, 56(%rax)
	movq	8(%rsp), %rcx
	addq	$64, %rax
	addq	$-64, %rcx
	movq	%rax, (%rsp)
	movq	%rcx, 8(%rsp)
	movl	64(%rsp), %eax
	incl	%eax
	movl	%eax, 64(%rsp)
Ljade_stream_chacha_chacha20_ietf_amd64_ref$7:
	movq	8(%rsp), %rax
	cmpq	$64, %rax
	jnb 	Ljade_stream_chacha_chacha20_ietf_amd64_ref$8
	cmpq	$0, %rax
	jbe 	Ljade_stream_chacha_chacha20_ietf_amd64_ref$1
	movl	76(%rsp), %eax
	movl	%eax, 80(%rsp)
	movl	16(%rsp), %eax
	movl	20(%rsp), %ecx
	movl	24(%rsp), %edx
	movl	28(%rsp), %esi
	movl	32(%rsp), %edi
	movl	36(%rsp), %r8d
	movl	40(%rsp), %r9d
	movl	44(%rsp), %r10d
	movl	48(%rsp), %r11d
	movl	52(%rsp), %ebx
	movl	56(%rsp), %ebp
	movl	60(%rsp), %r12d
	movl	64(%rsp), %r13d
	movl	68(%rsp), %r14d
	movl	72(%rsp), %r15d
	movl	%r15d, 84(%rsp)
	movl	$10, %r15d
Ljade_stream_chacha_chacha20_ietf_amd64_ref$6:
	movl	%r15d, 88(%rsp)
	movl	84(%rsp), %r15d
	addl	%edi, %eax
	addl	%r9d, %edx
	xorl	%eax, %r13d
	xorl	%edx, %r15d
	roll	$16, %r13d
	roll	$16, %r15d
	addl	%r13d, %r11d
	addl	%r15d, %ebp
	xorl	%r11d, %edi
	xorl	%ebp, %r9d
	roll	$12, %edi
	roll	$12, %r9d
	addl	%edi, %eax
	addl	%r9d, %edx
	xorl	%eax, %r13d
	xorl	%edx, %r15d
	roll	$8, %r13d
	roll	$8, %r15d
	addl	%r13d, %r11d
	addl	%r15d, %ebp
	xorl	%r11d, %edi
	xorl	%ebp, %r9d
	roll	$7, %edi
	roll	$7, %r9d
	movl	%r15d, 92(%rsp)
	movl	80(%rsp), %r15d
	addl	%r8d, %ecx
	addl	%r10d, %esi
	xorl	%ecx, %r14d
	xorl	%esi, %r15d
	roll	$16, %r14d
	roll	$16, %r15d
	addl	%r14d, %ebx
	addl	%r15d, %r12d
	xorl	%ebx, %r8d
	xorl	%r12d, %r10d
	roll	$12, %r8d
	roll	$12, %r10d
	addl	%r8d, %ecx
	addl	%r10d, %esi
	xorl	%ecx, %r14d
	xorl	%esi, %r15d
	roll	$8, %r14d
	roll	$8, %r15d
	addl	%r14d, %ebx
	addl	%r15d, %r12d
	xorl	%ebx, %r8d
	xorl	%r12d, %r10d
	roll	$7, %r8d
	roll	$7, %r10d
	addl	%r9d, %ecx
	addl	%r8d, %eax
	xorl	%ecx, %r13d
	xorl	%eax, %r15d
	roll	$16, %r13d
	roll	$16, %r15d
	addl	%r13d, %r12d
	addl	%r15d, %ebp
	xorl	%r12d, %r9d
	xorl	%ebp, %r8d
	roll	$12, %r9d
	roll	$12, %r8d
	addl	%r9d, %ecx
	addl	%r8d, %eax
	xorl	%ecx, %r13d
	xorl	%eax, %r15d
	roll	$8, %r13d
	roll	$8, %r15d
	addl	%r13d, %r12d
	addl	%r15d, %ebp
	xorl	%r12d, %r9d
	xorl	%ebp, %r8d
	roll	$7, %r9d
	roll	$7, %r8d
	movl	%r15d, 80(%rsp)
	movl	92(%rsp), %r15d
	addl	%r10d, %edx
	addl	%edi, %esi
	xorl	%edx, %r14d
	xorl	%esi, %r15d
	roll	$16, %r14d
	roll	$16, %r15d
	addl	%r14d, %r11d
	addl	%r15d, %ebx
	xorl	%r11d, %r10d
	xorl	%ebx, %edi
	roll	$12, %r10d
	roll	$12, %edi
	addl	%r10d, %edx
	addl	%edi, %esi
	xorl	%edx, %r14d
	xorl	%esi, %r15d
	roll	$8, %r14d
	roll	$8, %r15d
	addl	%r14d, %r11d
	addl	%r15d, %ebx
	xorl	%r11d, %r10d
	xorl	%ebx, %edi
	roll	$7, %r10d
	roll	$7, %edi
	movl	%r15d, 84(%rsp)
	movl	88(%rsp), %r15d
	decl	%r15d
	cmpl	$0, %r15d
	jnbe	Ljade_stream_chacha_chacha20_ietf_amd64_ref$6
	movl	84(%rsp), %r15d
	addl	16(%rsp), %eax
	addl	20(%rsp), %ecx
	addl	24(%rsp), %edx
	addl	28(%rsp), %esi
	addl	32(%rsp), %edi
	addl	36(%rsp), %r8d
	addl	40(%rsp), %r9d
	addl	44(%rsp), %r10d
	addl	48(%rsp), %r11d
	addl	52(%rsp), %ebx
	addl	56(%rsp), %ebp
	addl	60(%rsp), %r12d
	addl	64(%rsp), %r13d
	addl	68(%rsp), %r14d
	addl	72(%rsp), %r15d
	movl	%r15d, 84(%rsp)
	movl	80(%rsp), %r15d
	addl	76(%rsp), %r15d
	movl	%r15d, 80(%rsp)
	movl	84(%rsp), %r15d
	movl	%eax, 16(%rsp)
	movl	%ecx, 20(%rsp)
	movl	%edx, 24(%rsp)
	movl	%esi, 28(%rsp)
	movl	%edi, 32(%rsp)
	movl	%r8d, 36(%rsp)
	movl	%r9d, 40(%rsp)
	movl	%r10d, 44(%rsp)
	movl	%r11d, 48(%rsp)
	movl	%ebx, 52(%rsp)
	movl	%ebp, 56(%rsp)
	movl	%r12d, 60(%rsp)
	movl	%r13d, 64(%rsp)
	movl	%r14d, 68(%rsp)
	movl	%r15d, 72(%rsp)
	movl	80(%rsp), %eax
	movl	%eax, 76(%rsp)
	movq	(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	%rcx, %rdx
	shrq	$3, %rdx
	movq	$0, %rsi
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref$4
Ljade_stream_chacha_chacha20_ietf_amd64_ref$5:
	movq	16(%rsp,%rsi,8), %rdi
	movq	%rdi, (%rax,%rsi,8)
	incq	%rsi
Ljade_stream_chacha_chacha20_ietf_amd64_ref$4:
	cmpq	%rdx, %rsi
	jb  	Ljade_stream_chacha_chacha20_ietf_amd64_ref$5
	shlq	$3, %rsi
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref$2
Ljade_stream_chacha_chacha20_ietf_amd64_ref$3:
	movb	16(%rsp,%rsi), %dl
	movb	%dl, (%rax,%rsi)
	incq	%rsi
Ljade_stream_chacha_chacha20_ietf_amd64_ref$2:
	cmpq	%rcx, %rsi
	jb  	Ljade_stream_chacha_chacha20_ietf_amd64_ref$3
Ljade_stream_chacha_chacha20_ietf_amd64_ref$1:
	xorq	%rax, %rax
	movq	96(%rsp), %rbx
	movq	104(%rsp), %rbp
	movq	112(%rsp), %r12
	movq	120(%rsp), %r13
	movq	128(%rsp), %r14
	movq	136(%rsp), %r15
	movq	144(%rsp), %rsp
	ret 
_jade_stream_chacha_chacha20_ietf_amd64_ref_xor:
jade_stream_chacha_chacha20_ietf_amd64_ref_xor:
	movq	%rsp, %rax
	leaq	-160(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 152(%rsp)
	movq	%rbx, 104(%rsp)
	movq	%rbp, 112(%rsp)
	movq	%r12, 120(%rsp)
	movq	%r13, 128(%rsp)
	movq	%r14, 136(%rsp)
	movq	%r15, 144(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdx, 16(%rsp)
	movl	$1634760805, 24(%rsp)
	movl	$857760878, 28(%rsp)
	movl	$2036477234, 32(%rsp)
	movl	$1797285236, 36(%rsp)
	movl	(%r8), %eax
	movl	%eax, 40(%rsp)
	movl	4(%r8), %eax
	movl	%eax, 44(%rsp)
	movl	8(%r8), %eax
	movl	%eax, 48(%rsp)
	movl	12(%r8), %eax
	movl	%eax, 52(%rsp)
	movl	16(%r8), %eax
	movl	%eax, 56(%rsp)
	movl	20(%r8), %eax
	movl	%eax, 60(%rsp)
	movl	24(%r8), %eax
	movl	%eax, 64(%rsp)
	movl	28(%r8), %eax
	movl	%eax, 68(%rsp)
	movl	$0, 72(%rsp)
	movl	(%rcx), %eax
	movl	%eax, 76(%rsp)
	movl	4(%rcx), %eax
	movl	%eax, 80(%rsp)
	movl	8(%rcx), %eax
	movl	%eax, 84(%rsp)
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$7
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$8:
	movl	84(%rsp), %eax
	movl	%eax, 88(%rsp)
	movl	24(%rsp), %r14d
	movl	28(%rsp), %r13d
	movl	32(%rsp), %eax
	movl	36(%rsp), %r15d
	movl	40(%rsp), %ecx
	movl	44(%rsp), %edx
	movl	48(%rsp), %esi
	movl	52(%rsp), %edi
	movl	56(%rsp), %r8d
	movl	60(%rsp), %r9d
	movl	64(%rsp), %r10d
	movl	68(%rsp), %r11d
	movl	72(%rsp), %ebx
	movl	76(%rsp), %ebp
	movl	80(%rsp), %r12d
	movl	%r12d, 92(%rsp)
	movl	$10, %r12d
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$9:
	movl	%r12d, 96(%rsp)
	movl	92(%rsp), %r12d
	addl	%ecx, %r14d
	addl	%esi, %eax
	xorl	%r14d, %ebx
	xorl	%eax, %r12d
	roll	$16, %ebx
	roll	$16, %r12d
	addl	%ebx, %r8d
	addl	%r12d, %r10d
	xorl	%r8d, %ecx
	xorl	%r10d, %esi
	roll	$12, %ecx
	roll	$12, %esi
	addl	%ecx, %r14d
	addl	%esi, %eax
	xorl	%r14d, %ebx
	xorl	%eax, %r12d
	roll	$8, %ebx
	roll	$8, %r12d
	addl	%ebx, %r8d
	addl	%r12d, %r10d
	xorl	%r8d, %ecx
	xorl	%r10d, %esi
	roll	$7, %ecx
	roll	$7, %esi
	movl	%r12d, 100(%rsp)
	movl	88(%rsp), %r12d
	addl	%edx, %r13d
	addl	%edi, %r15d
	xorl	%r13d, %ebp
	xorl	%r15d, %r12d
	roll	$16, %ebp
	roll	$16, %r12d
	addl	%ebp, %r9d
	addl	%r12d, %r11d
	xorl	%r9d, %edx
	xorl	%r11d, %edi
	roll	$12, %edx
	roll	$12, %edi
	addl	%edx, %r13d
	addl	%edi, %r15d
	xorl	%r13d, %ebp
	xorl	%r15d, %r12d
	roll	$8, %ebp
	roll	$8, %r12d
	addl	%ebp, %r9d
	addl	%r12d, %r11d
	xorl	%r9d, %edx
	xorl	%r11d, %edi
	roll	$7, %edx
	roll	$7, %edi
	addl	%esi, %r13d
	addl	%edx, %r14d
	xorl	%r13d, %ebx
	xorl	%r14d, %r12d
	roll	$16, %ebx
	roll	$16, %r12d
	addl	%ebx, %r11d
	addl	%r12d, %r10d
	xorl	%r11d, %esi
	xorl	%r10d, %edx
	roll	$12, %esi
	roll	$12, %edx
	addl	%esi, %r13d
	addl	%edx, %r14d
	xorl	%r13d, %ebx
	xorl	%r14d, %r12d
	roll	$8, %ebx
	roll	$8, %r12d
	addl	%ebx, %r11d
	addl	%r12d, %r10d
	xorl	%r11d, %esi
	xorl	%r10d, %edx
	roll	$7, %esi
	roll	$7, %edx
	movl	%r12d, 88(%rsp)
	movl	100(%rsp), %r12d
	addl	%edi, %eax
	addl	%ecx, %r15d
	xorl	%eax, %ebp
	xorl	%r15d, %r12d
	roll	$16, %ebp
	roll	$16, %r12d
	addl	%ebp, %r8d
	addl	%r12d, %r9d
	xorl	%r8d, %edi
	xorl	%r9d, %ecx
	roll	$12, %edi
	roll	$12, %ecx
	addl	%edi, %eax
	addl	%ecx, %r15d
	xorl	%eax, %ebp
	xorl	%r15d, %r12d
	roll	$8, %ebp
	roll	$8, %r12d
	addl	%ebp, %r8d
	addl	%r12d, %r9d
	xorl	%r8d, %edi
	xorl	%r9d, %ecx
	roll	$7, %edi
	roll	$7, %ecx
	movl	%r12d, 92(%rsp)
	movl	96(%rsp), %r12d
	decl	%r12d
	cmpl	$0, %r12d
	jnbe	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$9
	movl	92(%rsp), %r12d
	addl	28(%rsp), %r13d
	addl	24(%rsp), %r14d
	movl	%r13d, %r13d
	shlq	$32, %r13
	movl	%r14d, %r14d
	xorq	%r14, %r13
	movq	8(%rsp), %r14
	xorq	(%r14), %r13
	addl	36(%rsp), %r15d
	addl	32(%rsp), %eax
	movl	%r15d, %r15d
	shlq	$32, %r15
	movl	%eax, %eax
	xorq	%rax, %r15
	xorq	8(%r14), %r15
	movq	(%rsp), %rax
	movq	%r13, (%rax)
	addl	44(%rsp), %edx
	addl	40(%rsp), %ecx
	movl	%edx, %edx
	shlq	$32, %rdx
	movl	%ecx, %ecx
	xorq	%rcx, %rdx
	xorq	16(%r14), %rdx
	movq	%r15, 8(%rax)
	addl	52(%rsp), %edi
	addl	48(%rsp), %esi
	movl	%edi, %ecx
	shlq	$32, %rcx
	movl	%esi, %esi
	xorq	%rsi, %rcx
	xorq	24(%r14), %rcx
	movq	%rdx, 16(%rax)
	addl	60(%rsp), %r9d
	addl	56(%rsp), %r8d
	movl	%r9d, %edx
	shlq	$32, %rdx
	movl	%r8d, %esi
	xorq	%rsi, %rdx
	xorq	32(%r14), %rdx
	movq	%rcx, 24(%rax)
	addl	68(%rsp), %r11d
	addl	64(%rsp), %r10d
	movl	%r11d, %ecx
	shlq	$32, %rcx
	movl	%r10d, %esi
	xorq	%rsi, %rcx
	xorq	40(%r14), %rcx
	movq	%rdx, 32(%rax)
	addl	76(%rsp), %ebp
	addl	72(%rsp), %ebx
	movl	%ebp, %edx
	shlq	$32, %rdx
	movl	%ebx, %esi
	xorq	%rsi, %rdx
	xorq	48(%r14), %rdx
	movq	%rcx, 40(%rax)
	movl	88(%rsp), %ecx
	addl	84(%rsp), %ecx
	addl	80(%rsp), %r12d
	movl	%ecx, %ecx
	shlq	$32, %rcx
	movl	%r12d, %esi
	xorq	%rsi, %rcx
	xorq	56(%r14), %rcx
	movq	%rdx, 48(%rax)
	movq	%rcx, 56(%rax)
	movq	16(%rsp), %rcx
	addq	$64, %rax
	addq	$64, %r14
	addq	$-64, %rcx
	movq	%rax, (%rsp)
	movq	%r14, 8(%rsp)
	movq	%rcx, 16(%rsp)
	movl	72(%rsp), %eax
	incl	%eax
	movl	%eax, 72(%rsp)
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$7:
	movq	16(%rsp), %rax
	cmpq	$64, %rax
	jnb 	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$8
	cmpq	$0, %rax
	jbe 	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$1
	movl	84(%rsp), %eax
	movl	%eax, 88(%rsp)
	movl	24(%rsp), %eax
	movl	28(%rsp), %ecx
	movl	32(%rsp), %edx
	movl	36(%rsp), %esi
	movl	40(%rsp), %edi
	movl	44(%rsp), %r8d
	movl	48(%rsp), %r9d
	movl	52(%rsp), %r10d
	movl	56(%rsp), %r11d
	movl	60(%rsp), %ebx
	movl	64(%rsp), %ebp
	movl	68(%rsp), %r12d
	movl	72(%rsp), %r13d
	movl	76(%rsp), %r14d
	movl	80(%rsp), %r15d
	movl	%r15d, 92(%rsp)
	movl	$10, %r15d
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$6:
	movl	%r15d, 96(%rsp)
	movl	92(%rsp), %r15d
	addl	%edi, %eax
	addl	%r9d, %edx
	xorl	%eax, %r13d
	xorl	%edx, %r15d
	roll	$16, %r13d
	roll	$16, %r15d
	addl	%r13d, %r11d
	addl	%r15d, %ebp
	xorl	%r11d, %edi
	xorl	%ebp, %r9d
	roll	$12, %edi
	roll	$12, %r9d
	addl	%edi, %eax
	addl	%r9d, %edx
	xorl	%eax, %r13d
	xorl	%edx, %r15d
	roll	$8, %r13d
	roll	$8, %r15d
	addl	%r13d, %r11d
	addl	%r15d, %ebp
	xorl	%r11d, %edi
	xorl	%ebp, %r9d
	roll	$7, %edi
	roll	$7, %r9d
	movl	%r15d, 100(%rsp)
	movl	88(%rsp), %r15d
	addl	%r8d, %ecx
	addl	%r10d, %esi
	xorl	%ecx, %r14d
	xorl	%esi, %r15d
	roll	$16, %r14d
	roll	$16, %r15d
	addl	%r14d, %ebx
	addl	%r15d, %r12d
	xorl	%ebx, %r8d
	xorl	%r12d, %r10d
	roll	$12, %r8d
	roll	$12, %r10d
	addl	%r8d, %ecx
	addl	%r10d, %esi
	xorl	%ecx, %r14d
	xorl	%esi, %r15d
	roll	$8, %r14d
	roll	$8, %r15d
	addl	%r14d, %ebx
	addl	%r15d, %r12d
	xorl	%ebx, %r8d
	xorl	%r12d, %r10d
	roll	$7, %r8d
	roll	$7, %r10d
	addl	%r9d, %ecx
	addl	%r8d, %eax
	xorl	%ecx, %r13d
	xorl	%eax, %r15d
	roll	$16, %r13d
	roll	$16, %r15d
	addl	%r13d, %r12d
	addl	%r15d, %ebp
	xorl	%r12d, %r9d
	xorl	%ebp, %r8d
	roll	$12, %r9d
	roll	$12, %r8d
	addl	%r9d, %ecx
	addl	%r8d, %eax
	xorl	%ecx, %r13d
	xorl	%eax, %r15d
	roll	$8, %r13d
	roll	$8, %r15d
	addl	%r13d, %r12d
	addl	%r15d, %ebp
	xorl	%r12d, %r9d
	xorl	%ebp, %r8d
	roll	$7, %r9d
	roll	$7, %r8d
	movl	%r15d, 88(%rsp)
	movl	100(%rsp), %r15d
	addl	%r10d, %edx
	addl	%edi, %esi
	xorl	%edx, %r14d
	xorl	%esi, %r15d
	roll	$16, %r14d
	roll	$16, %r15d
	addl	%r14d, %r11d
	addl	%r15d, %ebx
	xorl	%r11d, %r10d
	xorl	%ebx, %edi
	roll	$12, %r10d
	roll	$12, %edi
	addl	%r10d, %edx
	addl	%edi, %esi
	xorl	%edx, %r14d
	xorl	%esi, %r15d
	roll	$8, %r14d
	roll	$8, %r15d
	addl	%r14d, %r11d
	addl	%r15d, %ebx
	xorl	%r11d, %r10d
	xorl	%ebx, %edi
	roll	$7, %r10d
	roll	$7, %edi
	movl	%r15d, 92(%rsp)
	movl	96(%rsp), %r15d
	decl	%r15d
	cmpl	$0, %r15d
	jnbe	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$6
	movl	92(%rsp), %r15d
	addl	24(%rsp), %eax
	addl	28(%rsp), %ecx
	addl	32(%rsp), %edx
	addl	36(%rsp), %esi
	addl	40(%rsp), %edi
	addl	44(%rsp), %r8d
	addl	48(%rsp), %r9d
	addl	52(%rsp), %r10d
	addl	56(%rsp), %r11d
	addl	60(%rsp), %ebx
	addl	64(%rsp), %ebp
	addl	68(%rsp), %r12d
	addl	72(%rsp), %r13d
	addl	76(%rsp), %r14d
	addl	80(%rsp), %r15d
	movl	%r15d, 92(%rsp)
	movl	88(%rsp), %r15d
	addl	84(%rsp), %r15d
	movl	%r15d, 88(%rsp)
	movl	92(%rsp), %r15d
	movl	%eax, 24(%rsp)
	movl	%ecx, 28(%rsp)
	movl	%edx, 32(%rsp)
	movl	%esi, 36(%rsp)
	movl	%edi, 40(%rsp)
	movl	%r8d, 44(%rsp)
	movl	%r9d, 48(%rsp)
	movl	%r10d, 52(%rsp)
	movl	%r11d, 56(%rsp)
	movl	%ebx, 60(%rsp)
	movl	%ebp, 64(%rsp)
	movl	%r12d, 68(%rsp)
	movl	%r13d, 72(%rsp)
	movl	%r14d, 76(%rsp)
	movl	%r15d, 80(%rsp)
	movl	88(%rsp), %eax
	movl	%eax, 84(%rsp)
	movq	(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	16(%rsp), %rdx
	movq	%rdx, %rsi
	shrq	$3, %rsi
	movq	$0, %rdi
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$4
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$5:
	movq	(%rcx,%rdi,8), %r8
	xorq	24(%rsp,%rdi,8), %r8
	movq	%r8, (%rax,%rdi,8)
	incq	%rdi
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$4:
	cmpq	%rsi, %rdi
	jb  	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$5
	shlq	$3, %rdi
	jmp 	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$2
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$3:
	movb	(%rcx,%rdi), %sil
	xorb	24(%rsp,%rdi), %sil
	movb	%sil, (%rax,%rdi)
	incq	%rdi
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$2:
	cmpq	%rdx, %rdi
	jb  	Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$3
Ljade_stream_chacha_chacha20_ietf_amd64_ref_xor$1:
	xorq	%rax, %rax
	movq	104(%rsp), %rbx
	movq	112(%rsp), %rbp
	movq	120(%rsp), %r12
	movq	128(%rsp), %r13
	movq	136(%rsp), %r14
	movq	144(%rsp), %r15
	movq	152(%rsp), %rsp
	ret 
